{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7198e-bdcc-45a0-b6f9-3325bf31dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install yfinance pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf92ae-1e74-41b1-8c8a-979de29e739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "stocks = ['AAPL', 'GOOGL', 'MSFT']\n",
    "data = {}\n",
    "\n",
    "for stock in stocks:\n",
    "    df = yf.download(stock, start='2022-01-01', end='2024-12-31', interval='1d')\n",
    "    df.reset_index(inplace=True)\n",
    "    df['Stock'] = stock\n",
    "    data[stock] = df\n",
    "    df.to_csv(f'{stock}_data.csv', index=False) \n",
    "\n",
    "print(\"Data saved as CSV files for: \", list(data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc566a0b-6f3b-4e9e-a87b-9d95426574f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests vaderSentiment pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08613e1c-2a58-42c7-9297-d8fb4f1e01e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca3e88-c39e-4c05-8d6b-7d9072453514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datetime import datetime\n",
    "\n",
    "API_KEY = 'c81c5e7584cb4ed3bee6262657dcb527'\n",
    "stocks = {\n",
    "    \"AAPL\": \"Apple stock\",\n",
    "    \"GOOGL\": \"Google stock\",\n",
    "    \"MSFT\": \"Microsoft stock\"\n",
    "}\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "all_results = []\n",
    "\n",
    "for ticker, query in stocks.items():\n",
    "    print(f\"Fetching news for {ticker}...\")\n",
    "    url = f'https://newsapi.org/v2/everything?q={query}&language=en&sortBy=publishedAt&pageSize=100&apiKey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    articles = data.get('articles', [])\n",
    "    print(f\"  → Found {len(articles)} articles for {ticker}\")\n",
    "\n",
    "    for article in articles:\n",
    "        title = article['title']\n",
    "        published_at = article['publishedAt'][:10]\n",
    "        sentiment = analyzer.polarity_scores(title)\n",
    "        label = 'positive' if sentiment['compound'] >= 0.05 else 'negative' if sentiment['compound'] <= -0.05 else 'neutral'\n",
    "        all_results.append([ticker, published_at, article['source']['name'], title, sentiment['compound'], label])\n",
    "\n",
    "df = pd.DataFrame(all_results, columns=['ticker', 'date', 'source', 'headline', 'vader_score', 'vader_label'])\n",
    "df.to_csv('news_sentiment_data.csv', index=False)\n",
    "print(\"Combined sentiment data saved as 'news_sentiment_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918ca56-dd1e-4f8c-811d-8fb3ef653447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e74c87-c517-4982-92b8-b6d1c1e34612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc25c9b2-35a2-4b57-aec0-8417199ff1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b48665-f018-40b0-aea6-a5f388906590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tickers = ['AAPL', 'GOOGL', 'MSFT']\n",
    "\n",
    "for ticker in tickers:\n",
    "    df = yf.download(ticker, start=\"2024-03-01\", end=\"2024-04-01\", auto_adjust=True)\n",
    "    df.head()\n",
    "    if df.empty:\n",
    "        print(f\" No data for {ticker}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    df.reset_index(inplace=True)  \n",
    "    df['ticker'] = ticker         \n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b944c-bcc9-49f7-af04-09d1223c3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "API_KEY = 'ba32d4f4031a788c262f72ef57a1865a'\n",
    "\n",
    "stocks = {\n",
    "    \"AAPL\": \"Apple stock\",\n",
    "    \"GOOGL\": \"Google stock\",\n",
    "    \"MSFT\": \"Microsoft stock\"\n",
    "}\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "all_results = []\n",
    "\n",
    "def generate_monthly_ranges(start_date, end_date):\n",
    "    ranges = []\n",
    "    current = start_date\n",
    "    while current < end_date:\n",
    "        next_month = (current.replace(day=1) + timedelta(days=32)).replace(day=1)\n",
    "        ranges.append((current.strftime(\"%Y-%m-%d\"), next_month.strftime(\"%Y-%m-%d\")))\n",
    "        current = next_month\n",
    "    return ranges\n",
    "\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2025, 1, 1)\n",
    "monthly_ranges = generate_monthly_ranges(start_date, end_date)\n",
    "\n",
    "for ticker, query in stocks.items():\n",
    "    print(f\"\\n Fetching news for {ticker}...\")\n",
    "    for from_date, to_date in monthly_ranges:\n",
    "        print(f\"  → {from_date} to {to_date}\")\n",
    "        url = f\"https://gnews.io/api/v4/search?q={query}&from={from_date}&to={to_date}&lang=en&max=100&token={API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            articles = data.get('articles', [])\n",
    "\n",
    "            for article in articles:\n",
    "                title = article['title']\n",
    "                published_at = article['publishedAt'][:10]\n",
    "                sentiment = analyzer.polarity_scores(title)\n",
    "                label = 'positive' if sentiment['compound'] >= 0.05 else 'negative' if sentiment['compound'] <= -0.05 else 'neutral'\n",
    "                all_results.append([ticker, published_at, article['source']['name'], title, sentiment['compound'], label])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error during {from_date} → {to_date}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(all_results, columns=['ticker', 'date', 'source', 'headline', 'vader_score', 'vader_label'])\n",
    "df.to_csv('news_sentiment_gnews_full.csv', index=False)\n",
    "print(\"\\n Monthly sentiment data saved as 'news_sentiment_gnews_full.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54820f47-2b3b-4391-ad33-61712022acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28edbb78-c2e6-40d5-9b87-7f6449581eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "df = pd.read_csv('news_sentiment_gnews_full.csv') \n",
    "\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2025, 1, 1)\n",
    "\n",
    "def random_date(start, end):\n",
    "    delta = end - start\n",
    "    random_days = random.randint(0, delta.days - 1)\n",
    "    return start + timedelta(days=random_days)\n",
    "\n",
    "df['date'] = df['date'].apply(lambda x: random_date(start_date, end_date).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "df.to_csv('news_sentiment_data_randomized.csv', index=False)\n",
    "print(\" Randomized dates assigned and saved to 'news_sentiment_data_randomized.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926d45d-d2ee-4532-9a3a-e038081a8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37a7b1-2745-4030-93de-f0819dd397df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")  \n",
    "db = client[\"stock_prediction\"]  \n",
    "collection = db[\"merged_stock_gnews\"]  \n",
    "\n",
    "\n",
    "data = list(collection.find())\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['ticker', 'date'])\n",
    "\n",
    "features = []\n",
    "\n",
    "for ticker, group in df.groupby(\"ticker\"):\n",
    "    group = group.sort_values(\"date\").copy()\n",
    "\n",
    "    group['prev_close'] = group['close'].shift(1)\n",
    "    group['return'] = group['close'].pct_change()\n",
    "\n",
    "   \n",
    "    group['ma_3'] = group['close'].rolling(window=3).mean()\n",
    "    group['ma_7'] = group['close'].rolling(window=7).mean()\n",
    "\n",
    "    \n",
    "    group['diff_ma_3'] = group['close'] - group['ma_3']\n",
    "    group['diff_ma_7'] = group['close'] - group['ma_7']\n",
    "\n",
    "    group['volatility_3'] = group['return'].rolling(window=3).std()\n",
    "    group['volatility_7'] = group['return'].rolling(window=7).std()\n",
    "\n",
    "    group['future_close'] = group['close'].shift(-1)\n",
    "    group['future_return'] = (group['future_close'] - group['close']) / group['close']\n",
    "\n",
    "    features.append(group)\n",
    "\n",
    "\n",
    "features_df = pd.concat(features)\n",
    "features_df.dropna(inplace=True)  \n",
    "\n",
    "model_df = features_df[[\n",
    "    'ticker', 'date', 'close', 'avg_vader_score', 'news_count', 'return',\n",
    "    'ma_3', 'ma_7', 'diff_ma_3', 'diff_ma_7', 'volatility_3', 'volatility_7',\n",
    "    'future_return'\n",
    "]]\n",
    "\n",
    "print(model_df.head())\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "feature_cols = [\n",
    "    'close', 'avg_vader_score', 'news_count', 'return',\n",
    "    'ma_3', 'ma_7', 'diff_ma_3', 'diff_ma_7', 'volatility_3', 'volatility_7'\n",
    "]\n",
    "target_col = 'future_return'\n",
    "\n",
    "\n",
    "model_df = model_df.dropna(subset=feature_cols + [target_col])\n",
    "\n",
    "model_df = model_df.sort_values(by=\"date\")\n",
    "\n",
    "split_index = int(0.8 * len(model_df))\n",
    "train_df = model_df.iloc[:split_index]\n",
    "test_df = model_df.iloc[split_index:]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\" MSE: {mse:.5f}\")\n",
    "print(f\"R² Score: {r2:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712987b-cc31-4575-a2d2-18a60fcf36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_df[feature_cols + ['future_return']].corr()['future_return'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00443f-df84-4cb3-a0ff-81ecc63ae09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782c824-a9ff-48e6-b04d-dcec7739c3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068606c-063c-4e9e-97a1-8baf0ed03a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e1cd6-7501-44ee-8713-f63dc62ee142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\") \n",
    "db = client[\"stock_prediction\"]\n",
    "collection = db[\"merged_stock_gnews\"]\n",
    "data = list(collection.find())\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.drop(columns=[\"_id\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(by=[\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"return\"] = df.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "df[\"future_return\"] = df.groupby(\"ticker\")[\"close\"].pct_change(periods=3).shift(-3)\n",
    "\n",
    "df[\"ma_3\"] = df.groupby(\"ticker\")[\"close\"].transform(lambda x: x.rolling(3).mean())\n",
    "df[\"ma_7\"] = df.groupby(\"ticker\")[\"close\"].transform(lambda x: x.rolling(7).mean())\n",
    "\n",
    "df[\"diff_ma_3\"] = df[\"close\"] - df[\"ma_3\"]\n",
    "df[\"diff_ma_7\"] = df[\"close\"] - df[\"ma_7\"]\n",
    "\n",
    "df[\"volatility_3\"] = df.groupby(\"ticker\")[\"close\"].transform(lambda x: x.rolling(3).std())\n",
    "df[\"volatility_7\"] = df.groupby(\"ticker\")[\"close\"].transform(lambda x: x.rolling(7).std())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"label\"] = df[\"future_return\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "features = [\"close\", \"avg_vader_score\", \"news_count\", \"return\", \"ma_3\", \"ma_7\",\n",
    "            \"diff_ma_3\", \"diff_ma_7\", \"volatility_3\", \"volatility_7\"]\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "print(df[features + [\"label\"]].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f9fe2-b4ce-4135-a178-f83080fbe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"label\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\" Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = pd.Series(model.feature_importances_, index=features)\n",
    "importances.sort_values().plot(kind=\"barh\", figsize=(8, 6), title=\"Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67243c6-1225-4e46-8e70-b0b33f9182bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = df[features]\n",
    "y = df['future_return']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "plt.xlabel(\"Actual Future Return\")\n",
    "plt.ylabel(\"Predicted Future Return\")\n",
    "plt.title(\"Actual vs Predicted Return\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd8708-720c-48ba-98bd-cfca1d462781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7cc33-4d22-4442-b0bf-32c88f9d26a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0936e-b699-4c19-8745-e4840b3362f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c04731-bf46-4646-a051-379f20736c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
